{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32aa654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 16:37:57,712 - root - INFO - Test info\n",
      "2023-03-10 16:37:57,715 - root - DEBUG - Test debug\n",
      "2023-03-10 16:37:57,716 - root - ERROR - Test error\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Setup file handler\n",
    "fhandler = logging.FileHandler('my.log')\n",
    "fhandler.setLevel(logging.DEBUG)\n",
    "fhandler.setFormatter(formatter)\n",
    "\n",
    "# Configure stream handler for the cells\n",
    "chandler = logging.StreamHandler()\n",
    "chandler.setLevel(logging.DEBUG)\n",
    "chandler.setFormatter(formatter)\n",
    "\n",
    "# Add both handlers\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Show the handlers\n",
    "logger.handlers\n",
    "\n",
    "# Log Something\n",
    "logger.info(\"Test info\")\n",
    "logger.debug(\"Test debug\")\n",
    "logger.error(\"Test error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa04e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.ent_num = 10\n",
    "        self.rel_num = 10\n",
    "        self.dim = 100\n",
    "        self.neg_ratio = 100\n",
    "        self.batch_size = 100\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lambd = 0.00001\n",
    "        self.lr = 0.001\n",
    "        self.epochs = 30\n",
    "        self.ent_dim = 100\n",
    "        self.rel_dim = 100\n",
    "        self.data_path = \"../data/\"\n",
    "        self.data_name = \"FB15k-237\"\n",
    "        self.model_path = \"./models\"\n",
    "\n",
    "    def init_rel_ent(self, ent_num, rel_num):\n",
    "        self.ent_num = ent_num\n",
    "        self.rel_num = rel_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faaee909",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(NTN, self).__init__()\n",
    "        self.config = config\n",
    "        self.ent_emb = nn.Embedding(config.ent_num, config.ent_dim)\n",
    "        self.rel_emb = nn.Embedding(config.rel_num, config.rel_dim)\n",
    "\n",
    "        self.mr = nn.Parameter(torch.randn(config.rel_dim, config.ent_dim * config.ent_dim), requires_grad=True)\n",
    "        self.mr1 = nn.Parameter(torch.randn(config.ent_dim, config.rel_dim))\n",
    "\n",
    "        self.mr2 = nn.Parameter(torch.randn(config.ent_dim, config.rel_dim))\n",
    "\n",
    "        self.b = nn.Parameter(torch.randn(1, config.rel_dim))\n",
    "\n",
    "        self.init()\n",
    "        self.loss = nn.Softplus()\n",
    "\n",
    "    def init(self):\n",
    "        nn.init.xavier_normal_(self.ent_emb.weight.data)\n",
    "        nn.init.xavier_normal_(self.rel_emb.weight.data)\n",
    "        nn.init.xavier_normal_(self.mr.data)\n",
    "        nn.init.xavier_normal_(self.mr1.data)\n",
    "        nn.init.xavier_normal_(self.mr2.data)\n",
    "\n",
    "    def forward(self, h, r, t):\n",
    "        h_e = self.ent_emb(h)\n",
    "        r_e = self.rel_emb(r)\n",
    "        t_e = self.ent_emb(t)\n",
    "\n",
    "        mr1_res = torch.mm(h_e, self.mr1)\n",
    "        mr2_res = torch.mm(t_e, self.mr2)\n",
    "\n",
    "        expand_h = h_e.unsqueeze(0).repeat(self.config.rel_dim, 1, 1)\n",
    "        expand_t = t_e.unsqueeze(-1)\n",
    "        mr_res = torch.matmul(expand_h,\n",
    "                              self.mr.view(self.config.rel_dim, self.config.ent_dim, self.config.ent_dim)).permute(1, 0,\n",
    "                                                                                                                   2)\n",
    "        #         print(mr_res.shape)\n",
    "        mr_all = torch.matmul(mr_res, expand_t)\n",
    "        mr_all = mr_all.squeeze(-1)\n",
    "\n",
    "        return torch.sum(torch.tanh(mr_all + mr1_res + mr2_res + self.b) * r_e, -1)\n",
    "\n",
    "    def regularization(self):\n",
    "        return ((torch.norm(self.ent_emb.weight, 2) ** 2) + (torch.norm(self.rel_emb.weight, 2) ** 2) + (\n",
    "                torch.norm(self.mr) ** 2) + (torch.norm(self.mr1) ** 2) + (torch.norm(self.mr2) ** 2))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516b9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = Config()\n",
    "# h = torch.zeros(10).long()\n",
    "# r = torch.zeros(10).long()\n",
    "# t = torch.zeros(10).long()\n",
    "# print(config.ent_num, config.rel_num)\n",
    "# model = NTN(config)\n",
    "# x = model(h, r, t)\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fbb4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loadData:\n",
    "    def __init__(self, congfig):\n",
    "        self.path = congfig.data_path + congfig.data_name + \"/\"  #文件路径自己设置\n",
    "        self.rel2id = {}\n",
    "        self.ent2id = {}\n",
    "        self.data = {sql: self.read(sql) for sql in ['train', 'valid', 'test']}\n",
    "\n",
    "    def read(self, file_name):\n",
    "        with open(self.path + file_name + '.txt', 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        triples = []\n",
    "        for line in lines:\n",
    "            temp = line.strip().split()\n",
    "            triples.append((self.get_ent(temp[0]), self.get_rel(temp[1]), self.get_ent(temp[2])))\n",
    "        return triples\n",
    "\n",
    "    def get_ent(self, ent):\n",
    "        if not ent in self.ent2id.keys():\n",
    "            self.ent2id[ent] = len(self.ent2id)\n",
    "        return self.ent2id[ent]\n",
    "\n",
    "    def get_rel(self, rel):\n",
    "        if not rel in self.rel2id.keys():\n",
    "            self.rel2id[rel] = len(self.rel2id)\n",
    "        return self.rel2id[rel]\n",
    "\n",
    "    def ent_num(self):\n",
    "        return len(self.ent2id)\n",
    "\n",
    "    def rel_num(self):\n",
    "        return len(self.rel2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "199ab95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from random import randint, random, shuffle\n",
    "\n",
    "\n",
    "class MyTrainData(Dataset):\n",
    "    def __init__(self, loaddata, config):\n",
    "        super(MyTrainData, self).__init__()\n",
    "        self.data = loaddata.data['train']\n",
    "        self.config = config\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def randValue(self, value):\n",
    "        temp = randint(0, self.config.ent_num - 1)\n",
    "        while temp == value:\n",
    "            temp = randint(0, self.config.ent_num - 1)\n",
    "        return temp\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fact = self.data[index]\n",
    "        fact = np.expand_dims(fact, axis=0)\n",
    "\n",
    "        neg = np.repeat(fact, self.config.neg_ratio, axis=0)\n",
    "        for i in range(self.config.neg_ratio):\n",
    "            if random() < 0.5:\n",
    "                neg[i][0] = self.randValue(neg[i][0])\n",
    "            else:\n",
    "                neg[i][2] = self.randValue(neg[i][2])\n",
    "        fact = np.append(fact, 1)\n",
    "        neg = np.append(neg, -np.ones((self.config.neg_ratio, 1)), axis=1)\n",
    "        return torch.LongTensor(fact), torch.LongTensor(neg)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "308c9478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTestData(Dataset):\n",
    "    def __init__(self, loaddata, data_type):\n",
    "        self.data = loaddata.data[data_type]\n",
    "        self.ent_num = loaddata.ent_num()\n",
    "        self.loaddata = loaddata\n",
    "        self.all_facts = set(self.get_all_facts())\n",
    "\n",
    "    def get_all_facts(self):\n",
    "        triples = []\n",
    "        for sql in ['train', 'valid', 'test']:\n",
    "            for fact in self.loaddata.data[sql]:\n",
    "                triples.append(fact)\n",
    "        return triples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fact = self.data[index]\n",
    "        neg_tail = []\n",
    "        h, r, t = fact\n",
    "        for i in range(0, self.ent_num):\n",
    "            if t == i:\n",
    "                continue\n",
    "            neg_tail.append((h, r, i))\n",
    "\n",
    "        neg_tail = [fact] + list(set(neg_tail) - self.all_facts)\n",
    "\n",
    "        neg_head = []\n",
    "        for i in range(0, self.ent_num):\n",
    "            if h == i:\n",
    "                continue\n",
    "            neg_head.append((i, r, t))\n",
    "\n",
    "        neg_head = [fact] + list(set(neg_head) - self.all_facts)\n",
    "        return torch.LongTensor(neg_head), torch.LongTensor(neg_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "798e728a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Measure:\n",
    "    def __init__(self):\n",
    "        self.mrr = {'head': 0.0, 'tail': 0.0}\n",
    "        self.mr = {'head': 0.0, 'tail': 0.0}\n",
    "        self.hit1 = {'head': 0.0, 'tail': 0.0}\n",
    "        self.hit3 = {'head': 0.0, 'tail': 0.0}\n",
    "        self.hit10 = {'head': 0.0, 'tail': 0.0}\n",
    "\n",
    "    def updata(self, rank, head_tail):\n",
    "        if rank == 1:\n",
    "            self.hit1[head_tail] += 1\n",
    "        if rank <= 3:\n",
    "            self.hit3[head_tail] += 1\n",
    "        if rank <= 10:\n",
    "            self.hit10[head_tail] += 1\n",
    "        self.mr[head_tail] += rank\n",
    "        self.mrr[head_tail] += 1.0 / rank\n",
    "\n",
    "    def total_deal(self, fact_num):\n",
    "        print(\"---------result--------\")\n",
    "        logger.info('hit1:' + str((self.hit1['head'] + self.hit1['tail']) / fact_num))\n",
    "        logger.info('hit3:' + str((self.hit3['head'] + self.hit3['tail']) / fact_num))\n",
    "        logger.info('hit10:' + str((self.hit10['head'] + self.hit10['tail']) / fact_num))\n",
    "        logger.info('mr:' + str((self.mr['head'] + self.mr['tail']) / fact_num))\n",
    "        logger.info('mrr:' + str((self.mrr['head'] + self.mrr['tail']) / fact_num))\n",
    "        return (self.mrr['head'] + self.mrr['tail']) / fact_num\n",
    "\n",
    "    def init(self):\n",
    "        self.mrr = {'head': 0.0, 'tail': 0.0}\n",
    "        self.mr = {'head': 0.0, 'tail': 0.0}\n",
    "        self.hit1 = {'head': 0.0, 'tail': 0.0}\n",
    "        self.hit3 = {'head': 0.0, 'tail': 0.0}\n",
    "        self.hit10 = {'head': 0.0, 'tail': 0.0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91876b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, config, loaddata, model):\n",
    "        self.config = config\n",
    "        self.loaddata = loaddata\n",
    "        self.train_loader, self.valid_loader = self.init_data()\n",
    "        self.model = model.to(config.device)\n",
    "        self.measure = Measure()\n",
    "        self.fact_num = len(loaddata.data['valid'])\n",
    "\n",
    "    def init_data(self):\n",
    "        myTrainData = MyTrainData(self.loaddata, config)\n",
    "        train_loader = DataLoader(myTrainData, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "        myTestData = MyTestData(self.loaddata, 'valid')\n",
    "        valid_loader = DataLoader(myTestData, batch_size=1, shuffle=True)\n",
    "        return train_loader, valid_loader\n",
    "\n",
    "    def train(self):\n",
    "        best_acc = 0.0\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.config.lr)\n",
    "        for epoch in trange(1, self.config.epochs + 1):\n",
    "            self.model.train()\n",
    "            tot = 0.0\n",
    "            cn = 0\n",
    "            for i, (pos, neg) in enumerate(self.train_loader):\n",
    "                neg = neg.view(-1, neg.shape[-1])\n",
    "                data = torch.cat([pos, neg], dim=0)\n",
    "                index = [i for i in range(data.shape[0])]\n",
    "                shuffle(index)\n",
    "                data = data[index]\n",
    "                data = data.to(self.config.device)\n",
    "                h = data[:, 0]\n",
    "                #                 print(data.shape, self.config.batch_size)\n",
    "                r = data[:, 1]\n",
    "                t = data[:, 2]\n",
    "                labels = data[:, -1]\n",
    "                optimizer.zero_grad()\n",
    "                #                 print(h.max(),h.min(), t.max(), t.min())\n",
    "                scores = self.model(h, r, t)\n",
    "                #                 print(scores.shape)\n",
    "\n",
    "                loss = torch.sum(self.model.loss(-labels * scores)) + self.config.lambd * self.model.regularization() /h.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tot += loss.cpu().item()\n",
    "            cn = cn + 1\n",
    "        print(\"------loss:\" + str(tot / cn) + \"-------\")\n",
    "\n",
    "        self.model.eval()\n",
    "        self.measure.init()\n",
    "        for i, (head, tail) in enumerate(self.valid_loader):\n",
    "            head = head.view(-1, 3)\n",
    "            head = head.to(self.config.device)\n",
    "            #                 print(head.shape)\n",
    "            h = head[:, 0]\n",
    "            r = head[:, 1]\n",
    "            t = head[:, 2]\n",
    "            #                 print(h.max(),h.min(), t.max(), t.min())\n",
    "            score = self.model(h, r, t)\n",
    "            score = score.cpu().data.numpy()\n",
    "            rank = (score >= score[0]).sum()\n",
    "            self.measure.updata(rank, 'head')\n",
    "\n",
    "            tail = tail.view(-1, 3)\n",
    "            tail = tail.to(self.config.device)\n",
    "            h = tail[:, 0]\n",
    "            r = tail[:, 1]\n",
    "            t = tail[:, 2]\n",
    "            #                 print(h.max(),h.min(), t.max(), t.min())\n",
    "            #                 print(tail)\n",
    "            score = self.model(h, r, t)\n",
    "            score = score.cpu().data.numpy()\n",
    "            rank = (score >= score[0]).sum()\n",
    "            self.measure.updata(rank, 'tail')\n",
    "        acc = self.measure.total_deal(self.fact_num * 2)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            self.save_mode()\n",
    "\n",
    "\n",
    "def save_mode(self):\n",
    "    #模型存储路径\n",
    "    save_path = self.config.model_path + '/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    torch.save(self.model.state_dict(), save_path + config.data_name + \"_best_acc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "224edafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 237 cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [04:36<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [16], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# model.load_state_dict(torch.load(config.model_path+\"/\"+config.data_name+\"_best_acc.pkl\"))\u001B[39;00m\n\u001B[0;32m      8\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(config, loaddata, model)\n\u001B[1;32m----> 9\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [10], line 31\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     29\u001B[0m tot \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m     30\u001B[0m cn \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (pos, neg) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_loader):\n\u001B[0;32m     32\u001B[0m     neg \u001B[38;5;241m=\u001B[39m neg\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, neg\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m     33\u001B[0m     data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([pos, neg], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mD:\\Users\\24105\\anaconda3\\envs\\liyang_pytorch_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    529\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[1;32m--> 530\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    531\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    533\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    534\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32mD:\\Users\\24105\\anaconda3\\envs\\liyang_pytorch_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    569\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 570\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    571\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    572\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data)\n",
      "File \u001B[1;32mD:\\Users\\24105\\anaconda3\\envs\\liyang_pytorch_py39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\Users\\24105\\anaconda3\\envs\\liyang_pytorch_py39\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfetch\u001B[39m(\u001B[38;5;28mself\u001B[39m, possibly_batched_index):\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn [6], line 33\u001B[0m, in \u001B[0;36mMyTrainData.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     31\u001B[0m fact \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(fact, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     32\u001B[0m neg \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mappend(neg, \u001B[38;5;241m-\u001B[39mnp\u001B[38;5;241m.\u001B[39mones((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mneg_ratio, \u001B[38;5;241m1\u001B[39m)), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mLongTensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfact\u001B[49m\u001B[43m)\u001B[49m, torch\u001B[38;5;241m.\u001B[39mLongTensor(neg)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "loaddata = loadData(config)\n",
    "config.init_rel_ent(loaddata.ent_num(), loaddata.rel_num())\n",
    "print(config.batch_size, config.rel_num, config.device)\n",
    "model = NTN(config)\n",
    "# model.load_state_dict(torch.load(config.model_path+\"/\"+config.data_name+\"_best_acc.pkl\"))\n",
    "\n",
    "trainer = Trainer(config, loaddata, model)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef77b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, model, loaddata, config):\n",
    "        self.loaddata = loaddata\n",
    "        self.test_loader = self.loadTest()\n",
    "        self.measure = Measure()\n",
    "        self.fact_num = len(loaddata.data['test'])\n",
    "        self.config = config\n",
    "        self.model = model.to(config.device)\n",
    "\n",
    "    def loadTest(self):\n",
    "        myTestData = MyTestData(self.loaddata, 'test')\n",
    "        test_loader = DataLoader(myTestData, batch_size=1, shuffle=True)\n",
    "        return test_loader\n",
    "\n",
    "    def test(self):\n",
    "        for i, (head, tail) in enumerate(self.test_loader):\n",
    "            head = head.view(-1, 3)\n",
    "            head = head.to(self.config.device)\n",
    "            h = head[:, 0]\n",
    "            r = head[:, 1]\n",
    "            t = head[:, 2]\n",
    "            score = self.model(h, r, t)\n",
    "            score = score.cpu().data.numpy()\n",
    "            rank = (score >= score[0]).sum()\n",
    "            self.measure.updata(rank, 'head')\n",
    "\n",
    "            tail = tail.view(-1, 3)\n",
    "            tail = tail.to(self.config.device)\n",
    "            h = tail[:, 0]\n",
    "            r = tail[:, 1]\n",
    "            t = tail[:, 2]\n",
    "            score = self.model(h, r, t)\n",
    "            score = score.cpu().data.numpy()\n",
    "            rank = (score >= score[0]).sum()\n",
    "            self.measure.updata(rank, 'tail')\n",
    "        self.measure.total_deal(self.fact_num * 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "800e92a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 08:20:51,455 - root - INFO - hit1:0.11382292582820287\n",
      "2022-05-05 08:20:51,456 - root - INFO - hit3:0.22092739177171894\n",
      "2022-05-05 08:20:51,456 - root - INFO - hit10:0.39130753444737615\n",
      "2022-05-05 08:20:51,457 - root - INFO - mr:270.7241522525164\n",
      "2022-05-05 08:20:51,457 - root - INFO - mrr:0.2029397597501765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------result--------\n"
     ]
    }
   ],
   "source": [
    "print(config.device)\n",
    "model.load_state_dict(torch.load(config.model_path + \"/\" + config.data_name + \"_best_acc.pkl\"))\n",
    "tester = Tester(model, loaddata, config)\n",
    "tester.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ec95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
